{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Text Input**"
      ],
      "metadata": {
        "id": "ExP4_mKLkbah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph=\"\"\"My dear young friends, dream, dream, dream. Dreams transform into thoughts and thoughts result in action. You have to dream before your dreams can come true. You should have a goal and a constant quest to acquire knowledge. Hard work and perseverance are essential. Use technology for the benefit of humankind and not for its destruction. The ignited mind of the youth is the most powerful resource on the earth, above the earth, and under the earth. When the student is ready, the teacher will appear. Aim high, dream big, and work hard to achieve those dreams. The future belongs to the young who have the courage to dream and the determination to realize those dreams. Remember, small aim is a crime; have great aim and pursue it with all your heart.\"\"\""
      ],
      "metadata": {
        "id": "LRACI7lukNpl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stemming:\n",
        "Stemming is a text normalization technique used in Natural Language Processing (NLP) to reduce words to their base or root form. The goal of stemming is to group together different forms of the same word so they can be analyzed as a single item. This helps in reducing the complexity of the data without losing significant meaning.\n",
        "\n"
      ],
      "metadata": {
        "id": "pgc4jn7ojQAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming Techniques\n",
        "\n",
        "**Common Stemming Algorithms**\n",
        "\n",
        "* **Porter Stemmer:** One of the most widely used stemming algorithms, developed by Martin Porter in 1980. It uses a series of rules to iteratively strip suffixes from words.\n",
        "* **Snowball Stemmer:**An improvement over the Porter Stemmer, also developed by Martin Porter. It supports multiple languages and is more efficient.\n",
        "* **Lancaster Stemmer:** Another alternative, known for being more aggressive than the Porter and Snowball stemmers."
      ],
      "metadata": {
        "id": "pj4JunY3jVdx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9KRUsXlOu5T",
        "outputId": "eada279c-6136-4d1e-9878-24b86a3ced80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Porter Stemmer"
      ],
      "metadata": {
        "id": "qlPWv339lj6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import punkt\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VhbOeMFj0N-",
        "outputId": "1a8deffd-f4e9-4d21-eb4c-1d82e326c1a9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences= nltk.sent_tokenize(paragraph)\n",
        "stemmer= PorterStemmer()\n"
      ],
      "metadata": {
        "id": "98WeKk5_j3qM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsEhXiRDj8lX",
        "outputId": "05a66c17-a3cc-461b-bee4-b6c57a23c2f8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stemming\n",
        "for i in range (len(sentences)):\n",
        "  words=nltk.word_tokenize(sentences[i])\n",
        "  words=[stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "  sentences[i]=' '.join(words)\n"
      ],
      "metadata": {
        "id": "q2l8XPdHkAPq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_paragraph = ' '.join(sentences)\n",
        "\n",
        "print(\"Original Paragraph:\")\n",
        "print(paragraph)\n",
        "print(\"\\nStemmed Paragraph:\")\n",
        "print(stemmed_paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS74vI_AkH_p",
        "outputId": "60b6c25f-e0e3-4f8e-dad6-3f9891de404b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Paragraph:\n",
            "My dear young friends, dream, dream, dream. Dreams transform into thoughts and thoughts result in action. You have to dream before your dreams can come true. You should have a goal and a constant quest to acquire knowledge. Hard work and perseverance are essential. Use technology for the benefit of humankind and not for its destruction. The ignited mind of the youth is the most powerful resource on the earth, above the earth, and under the earth. When the student is ready, the teacher will appear. Aim high, dream big, and work hard to achieve those dreams. The future belongs to the young who have the courage to dream and the determination to realize those dreams. Remember, small aim is a crime; have great aim and pursue it with all your heart.\n",
            "\n",
            "Stemmed Paragraph:\n",
            "my dear young friend , dream , dream , dream . dream transform thought thought result action . you dream dream come true . you goal constant quest acquir knowledg . hard work persever essenti . use technolog benefit humankind destruct . the ignit mind youth power resourc earth , earth , earth . when student readi , teacher appear . aim high , dream big , work hard achiev dream . the futur belong young courag dream determin realiz dream . rememb , small aim crime ; great aim pursu heart .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Snowball Stemming"
      ],
      "metadata": {
        "id": "ZdqA6mWIlAwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "# Initialize the stemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "# List of words to stem\n",
        "#words = [\"running\", \"runner\", \"ran\", \"easily\", \"fairly\"]\n",
        "words=nltk.word_tokenize(paragraph)\n",
        "\n",
        "# Apply stemming\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvU-3xaTlJTZ",
        "outputId": "5f522aad-b1b5-4240-f2d1-cd019586dbb5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['my', 'dear', 'young', 'friend', ',', 'dream', ',', 'dream', ',', 'dream', '.', 'dream', 'transform', 'into', 'thought', 'and', 'thought', 'result', 'in', 'action', '.', 'you', 'have', 'to', 'dream', 'befor', 'your', 'dream', 'can', 'come', 'true', '.', 'you', 'should', 'have', 'a', 'goal', 'and', 'a', 'constant', 'quest', 'to', 'acquir', 'knowledg', '.', 'hard', 'work', 'and', 'persever', 'are', 'essenti', '.', 'use', 'technolog', 'for', 'the', 'benefit', 'of', 'humankind', 'and', 'not', 'for', 'it', 'destruct', '.', 'the', 'ignit', 'mind', 'of', 'the', 'youth', 'is', 'the', 'most', 'power', 'resourc', 'on', 'the', 'earth', ',', 'abov', 'the', 'earth', ',', 'and', 'under', 'the', 'earth', '.', 'when', 'the', 'student', 'is', 'readi', ',', 'the', 'teacher', 'will', 'appear', '.', 'aim', 'high', ',', 'dream', 'big', ',', 'and', 'work', 'hard', 'to', 'achiev', 'those', 'dream', '.', 'the', 'futur', 'belong', 'to', 'the', 'young', 'who', 'have', 'the', 'courag', 'to', 'dream', 'and', 'the', 'determin', 'to', 'realiz', 'those', 'dream', '.', 'rememb', ',', 'small', 'aim', 'is', 'a', 'crime', ';', 'have', 'great', 'aim', 'and', 'pursu', 'it', 'with', 'all', 'your', 'heart', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lancaster Stemmer method"
      ],
      "metadata": {
        "id": "p3JEH6LvlR6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "# Download necessary NLTK data files\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Initialize the Lancaster Stemmer\n",
        "stemmer = LancasterStemmer()\n",
        "# Tokenize the paragraph into sentences\n",
        "sentences = sent_tokenize(paragraph)\n",
        "\n",
        "# Process each sentence\n",
        "for i in range(len(sentences)):\n",
        "    words = word_tokenize(sentences[i])\n",
        "    words = [stemmer.stem(word) for word in words if word.lower() not in set(stopwords.words('english'))]\n",
        "    sentences[i] = ' '.join(words)\n",
        "\n",
        "# Reconstruct the paragraph from processed sentences\n",
        "stemmed_paragraph = ' '.join(sentences)\n",
        "\n",
        "print(\"Original Paragraph:\")\n",
        "print(paragraph)\n",
        "print(\"\\nStemmed Paragraph:\")\n",
        "print(stemmed_paragraph.split(\" \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSmNmtmvlcRL",
        "outputId": "5ca70cbb-3325-483a-b0f2-a14360eef7dd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Paragraph:\n",
            "My dear young friends, dream, dream, dream. Dreams transform into thoughts and thoughts result in action. You have to dream before your dreams can come true. You should have a goal and a constant quest to acquire knowledge. Hard work and perseverance are essential. Use technology for the benefit of humankind and not for its destruction. The ignited mind of the youth is the most powerful resource on the earth, above the earth, and under the earth. When the student is ready, the teacher will appear. Aim high, dream big, and work hard to achieve those dreams. The future belongs to the young who have the courage to dream and the determination to realize those dreams. Remember, small aim is a crime; have great aim and pursue it with all your heart.\n",
            "\n",
            "Stemmed Paragraph:\n",
            "['dear', 'young', 'friend', ',', 'dream', ',', 'dream', ',', 'dream', '.', 'dream', 'transform', 'thought', 'thought', 'result', 'act', '.', 'dream', 'dream', 'com', 'tru', '.', 'goal', 'const', 'quest', 'acquir', 'knowledg', '.', 'hard', 'work', 'persev', 'ess', '.', 'us', 'technolog', 'benefit', 'humankind', 'destruct', '.', 'ignit', 'mind', 'you', 'pow', 'resourc', 'ear', ',', 'ear', ',', 'ear', '.', 'stud', 'ready', ',', 'teach', 'appear', '.', 'aim', 'high', ',', 'dream', 'big', ',', 'work', 'hard', 'achiev', 'dream', '.', 'fut', 'belong', 'young', 'cour', 'dream', 'determin', 'real', 'dream', '.', 'rememb', ',', 'smal', 'aim', 'crim', ';', 'gre', 'aim', 'pursu', 'heart', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regex-based Stemmer\n",
        "A simpler approach where custom regular expressions are used to remove common suffixes from words. This method can be useful for specific applications but is less flexible and powerful than other stemmers."
      ],
      "metadata": {
        "id": "2V4SjJMql1wO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "def regex_stemmer(word):\n",
        "    patterns = [\n",
        "        (r'ing$', ''),\n",
        "        (r'ed$', ''),\n",
        "        (r'ly$', ''),\n",
        "        (r'es$', ''),\n",
        "        (r's$', ''),\n",
        "    ]\n",
        "    for pattern, replacement in patterns:\n",
        "        word = re.sub(pattern, replacement, word)\n",
        "    return word\n",
        "\n",
        "# Tokenize the paragraph into sentences\n",
        "sentences = sent_tokenize(paragraph)\n",
        "\n",
        "# Process each sentence\n",
        "for i in range(len(sentences)):\n",
        "    words = word_tokenize(sentences[i])\n",
        "    words = [regex_stemmer(word) for word in words]\n",
        "    sentences[i] = ' '.join(words)\n",
        "\n",
        "# Reconstruct the paragraph from processed sentences\n",
        "stemmed_paragraph = ' '.join(sentences)\n",
        "\n",
        "print(\"Original Paragraph:\")\n",
        "print(paragraph)\n",
        "print(\"\\nStemmed Paragraph:\")\n",
        "print(stemmed_paragraph)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDSsN4C-l8cn",
        "outputId": "bf26748c-803c-4ee8-ea01-bd1bb7dc96fb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Paragraph:\n",
            "My dear young friends, dream, dream, dream. Dreams transform into thoughts and thoughts result in action. You have to dream before your dreams can come true. You should have a goal and a constant quest to acquire knowledge. Hard work and perseverance are essential. Use technology for the benefit of humankind and not for its destruction. The ignited mind of the youth is the most powerful resource on the earth, above the earth, and under the earth. When the student is ready, the teacher will appear. Aim high, dream big, and work hard to achieve those dreams. The future belongs to the young who have the courage to dream and the determination to realize those dreams. Remember, small aim is a crime; have great aim and pursue it with all your heart.\n",
            "\n",
            "Stemmed Paragraph:\n",
            "My dear young friend , dream , dream , dream . Dream transform into thought and thought result in action . You have to dream before your dream can come true . You should have a goal and a constant quest to acquire knowledge . Hard work and perseverance are essential . Use technology for the benefit of humankind and not for it destruction . The ignit mind of the youth i the most powerful resource on the earth , above the earth , and under the earth . When the student i ready , the teacher will appear . Aim high , dream big , and work hard to achieve those dream . The future belong to the young who have the courage to dream and the determination to realize those dream . Remember , small aim i a crime ; have great aim and pursue it with all your heart .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lovins Stemmer\n",
        "The Lovins Stemmer, developed by Julie Beth Lovins in 1968, is one of the oldest stemming algorithms. It removes the longest suffix from a word and uses a large list of irregular forms.\n",
        "\n",
        "Example:\n",
        "The Lovins Stemmer is not available in popular NLP libraries like NLTK or SpaCy, but it can be implemented with custom logic if needed."
      ],
      "metadata": {
        "id": "4G4CeuoJme4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "def lovins_stemmer(word):\n",
        "    patterns = [\n",
        "        (r'ations$', 'ate'),\n",
        "        (r'ingly$', 'ingli'),\n",
        "        (r'ed$', ''),\n",
        "        (r'ing$', ''),\n",
        "        (r'es$', ''),\n",
        "        (r's$', ''),\n",
        "    ]\n",
        "    for pattern, replacement in patterns:\n",
        "        if re.search(pattern, word):\n",
        "            return re.sub(pattern, replacement, word)\n",
        "    return word\n",
        "\n",
        "\n",
        "\n",
        "# Tokenize the paragraph into sentences\n",
        "sentences = sent_tokenize(paragraph)\n",
        "\n",
        "# Process each sentence\n",
        "for i in range(len(sentences)):\n",
        "    words = word_tokenize(sentences[i])\n",
        "    words = [lovins_stemmer(word) for word in words]\n",
        "    sentences[i] = ' '.join(words)\n",
        "\n",
        "# Reconstruct the paragraph from processed sentences\n",
        "stemmed_paragraph = ' '.join(sentences)\n",
        "\n",
        "print(\"Original Paragraph:\")\n",
        "print(paragraph)\n",
        "print(\"\\nStemmed Paragraph:\")\n",
        "print(stemmed_paragraph)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kch-SfsEm-rz",
        "outputId": "89fea44d-c306-4678-bcc7-2a163d7fd95a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Paragraph:\n",
            "My dear young friends, dream, dream, dream. Dreams transform into thoughts and thoughts result in action. You have to dream before your dreams can come true. You should have a goal and a constant quest to acquire knowledge. Hard work and perseverance are essential. Use technology for the benefit of humankind and not for its destruction. The ignited mind of the youth is the most powerful resource on the earth, above the earth, and under the earth. When the student is ready, the teacher will appear. Aim high, dream big, and work hard to achieve those dreams. The future belongs to the young who have the courage to dream and the determination to realize those dreams. Remember, small aim is a crime; have great aim and pursue it with all your heart.\n",
            "\n",
            "Stemmed Paragraph:\n",
            "My dear young friend , dream , dream , dream . Dream transform into thought and thought result in action . You have to dream before your dream can come true . You should have a goal and a constant quest to acquire knowledge . Hard work and perseverance are essential . Use technology for the benefit of humankind and not for it destruction . The ignit mind of the youth i the most powerful resource on the earth , above the earth , and under the earth . When the student i ready , the teacher will appear . Aim high , dream big , and work hard to achieve those dream . The future belong to the young who have the courage to dream and the determination to realize those dream . Remember , small aim i a crime ; have great aim and pursue it with all your heart .\n"
          ]
        }
      ]
    }
  ]
}